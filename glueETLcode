import sys
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job

## @params: [JOB_NAME]
args = getResolvedOptions(sys.argv, ['JOB_NAME'])

sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)
## @type: DataSource
## @args: [database = "hssetl", table_name = "hospital", transformation_ctx = "datasource0"]
## @return: datasource0
## @inputs: []
datasource0 = glueContext.create_dynamic_frame.from_catalog(database = "hssetl", table_name = "hospital", transformation_ctx = "datasource0")
## @type: ApplyMapping
## @args: [mapping = [("facility id", "long", "facility id", "long"), ("hospital name", "string", "hospital name", "string"), ("indicator name", "string", "indicator name", "string"), ("year", "long", "year", "long"), ("infections observed", "long", "infections observed", "long"), ("infections predicted", "double", "infections predicted", "double"), ("denominator", "long", "denominator", "long"), ("indicator value", "double", "indicator value", "double"), ("indicator lower confidence limit", "double", "indicator lower confidence limit", "double"), ("indicator upper confidence limit", "double", "indicator upper confidence limit", "double"), ("indicator units", "string", "indicator units", "string"), ("comparison results", "string", "comparison results", "string")], transformation_ctx = "applymapping1"]
## @return: applymapping1
## @inputs: [frame = datasource0]
applymapping1 = ApplyMapping.apply(frame = datasource0, mappings = [("facility id", "long", "facility id", "long"), ("hospital name", "string", "hospital name", "string"), ("indicator name", "string", "indicator name", "string"), ("year", "long", "year", "long"), ("infections observed", "long", "infections observed", "long"), ("infections predicted", "double", "infections predicted", "double"), ("denominator", "long", "denominator", "long"), ("indicator value", "double", "indicator value", "double"), ("indicator lower confidence limit", "double", "indicator lower confidence limit", "double"), ("indicator upper confidence limit", "double", "indicator upper confidence limit", "double"), ("indicator units", "string", "indicator units", "string"), ("comparison results", "string", "comparison results", "string")], transformation_ctx = "applymapping1")
## @type: DataSink
## @args: [connection_type = "s3", connection_options = {"path": "s3://etloutputsample"}, format = "json", transformation_ctx = "datasink2"]
## @return: datasink2
## @inputs: [frame = applymapping1]
datasink2 = glueContext.write_dynamic_frame.from_options(frame = applymapping1, connection_type = "s3", connection_options = {"path": "s3://etloutputsample"}, format = "json", transformation_ctx = "datasink2")
job.commit()
